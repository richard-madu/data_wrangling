{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting: wragle_report¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After gathering all the data from their individual sources. The cleaning process was carried out programmatically using pandas cleaning methods. Before cleaning it is important to assess the data to get familiar to the data and spot some key issues that would make cause the data to give a baised results in the analysis stage. The cleaning process is divided in to quality issues and tidiness issues. Data quality issues can stem from duplicate data, unstructured data, incomplete data, different data formats, or the difficulty accessing the data. Tidy data is a standard way of mapping the meaning of a dataset to its structure. A dataset is messy or tidy depending on how rows, columns and tables are matched up with observations, variables and types. Tidy datasets provide a standardized way to link the structure of a dataset (its physical layout) with its semantics (its meaning). In tidy data: \n",
    "1. Each variable forms a column.\n",
    " 2. Each observation forms a row. \n",
    "3. Each type of observational unit forms a table\n",
    "In summary quality issues are content issues while tidiness issues are structural issues\n",
    "QUALITY ISSUES\n",
    "•\tIn the dataset gather there are a few quality issues that was treated the first is dropping all the retweets. In this project, we are required to analyze tweets from the dog_rate twitter handle and in the data sent to udacity retweets were included. I used this code to drop the  rows that are retweets:\n",
    "\n",
    "twitter_archive_copy.drop(twitter_archive_copy[twitter_archive_copy['retweeted_status_id'].notna()].index, inplace = True)\n",
    "\n",
    "The rationale for the code is to drop the rows that has a non-na value in the retweet_status _id column. Furthermore, I removed other columns that are associated with retweets.\n",
    "•\tThe next quality issue treated in this project was incorrect datatype. The tweet_id of the three was converted from int to str. This was done so mathematic operation can be carried out on the twee_id. Similarly, the timestamp in the twitter archive dataset is a string and it was changed to a datetime datatype\n",
    "\n",
    "•\tAfterwards, I dropped the nan values of the expanded_url using the dropna function\n",
    "\n",
    "•\tSubsequently, There are names in the name column that are not valid like; None, not, officially. I dropped them because it made no sense.\n",
    "\n",
    "•\tFinally, I looked in to the names and noticed that the capitalizing pattern were not uniform so I restructured them to have a uniform structure by capitalizing all the only the first letter of each word. This same issue was treated in the image-prediction data set in columns p1, p2, p3 and this same methodology was used to resolve.\n",
    "\n",
    "TIDINESS ISSUES\n",
    "\n",
    "In this project only 2 tidiness\n",
    "•\tAccording to Hadley Wickham (2014) for a data to be tidy it should fulfil the following conditions\n",
    "    1. Each variable forms a column.\n",
    "    2. Each observation forms a row.\n",
    "    3. Each type of observational unit forms a table\n",
    "The text column in the twitter archive has more than one observation; it has the text, rating and url. I used the split function in pandas to remove the url and the rating from the text.\n",
    "•\tAfterwards, I added the columns of the data I queried from twitter API to the twitter archive as I consider them to be of the same observational unit  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
